{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4ed583c-6064-49b2-bccd-bc5d782acebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter filename from 'docs/' to analyze:  Naveen_Singh_Naveen_Prasad_Singh_vs_State_Of_Bihar_Anr_on_21_June_2017.PDF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing: Naveen_Singh_Naveen_Prasad_Singh_vs_State_Of_Bihar_Anr_on_21_June_2017.PDF\n",
      "Extracted: ['IPC_304B', 'IPC_302', 'IPC_34', 'CrPC_313', 'CrPC_354', 'CrPC_386', 'CrPC_304B', 'Evidence_Act_106', 'Evidence_Act_114']\n",
      "\n",
      "============================================================\n",
      "TOP 5 SUGGESTIONS & CONFIDENCE METRICS\n",
      "============================================================\n",
      "Section: IPC_307              | Confidence: 1.00 | ████████████████████\n",
      "   Context: \"offence under Section PPS 111 of 121 Conf 3-13 .doc 324 of the Indian Penal Code...\"\n",
      "Section: IPC_299              | Confidence: 1.00 | ████████████████████\n",
      "   Context: \"fences of culpable homicide, culpable homicide amounting to murder and\n",
      "culpable ...\"\n",
      "Section: IPC_300              | Confidence: 1.00 | ████████████████████\n",
      "   Context: \"Referring to these Sections it was submitted by the learned Additional Public Pr...\"\n",
      "Section: IPC_304              | Confidence: 1.00 | ████████████████████\n",
      "   Context: \"r the offence under section 304 of the Indian  Penal   Code I  am   also of  \n",
      "th...\"\n",
      "Section: CrPC_161             | Confidence: 1.00 | ████████████████████\n",
      "   Context: \"he had told him that Udai Singh had thrown acid on her The submission of learned...\"\n",
      "------------------------------------------------------------\n",
      "Average Model Confidence: 1.0000\n",
      "Metric: Model is VERY CERTAIN about these missing sections.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# BLOCK 2: ANALYSIS & MATCH SCORE EVALUATION (FIXED)\n",
    "# ==========================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import PyPDF2\n",
    "import docx\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "from collections import defaultdict\n",
    "\n",
    "# --- HELPER FUNCTIONS ---\n",
    "ACT_PATTERNS = {\n",
    "    'IPC': [ r'Section\\s+(\\d+[A-Z]*)\\s+(?:of\\s+)?(?:the\\s+)?(?:Indian\\s+Penal\\s+Code|IPC)', r'(\\d+[A-Z]*)\\s+(?:IPC|Indian\\s+Penal\\s+Code)' ],\n",
    "    'CrPC': [ r'Section\\s+(\\d+[A-Z]*)\\s+(?:of\\s+)?(?:the\\s+)?(?:Cr\\.?P\\.?C\\.?|CrPC)', r'(?:Cr\\.?P\\.?C\\.?|CrPC)\\s+(?:Section\\s+)?(\\d+[A-Z]*)' ],\n",
    "    'Evidence_Act': [ r'Section\\s+(\\d+[A-Z]*)\\s+(?:of\\s+)?(?:the\\s+)?Evidence\\s+Act' ],\n",
    "    'Arbitration_Act': [ r'Section\\s+(\\d+[A-Z]*)\\s+(?:of\\s+)?(?:the\\s+)?Arbitration\\s+Act' ],\n",
    "    'Contract_Act': [ r'Section\\s+(\\d+[A-Z]*)\\s+(?:of\\s+)?(?:the\\s+)?Contract\\s+Act' ],\n",
    "    'Partnership_Act': [ r'Section\\s+(\\d+[A-Z]*)\\s+(?:of\\s+)?(?:the\\s+)?Partnership\\s+Act' ]\n",
    "}\n",
    "\n",
    "def check_pdf_type(path):\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            reader = PyPDF2.PdfReader(f)\n",
    "            text = \"\"\n",
    "            for page in reader.pages[:2]: text += page.extract_text()\n",
    "            return 'text' if len(text.strip()) >= 100 else 'scanned'\n",
    "    except: return 'scanned'\n",
    "\n",
    "def get_document_text(path):\n",
    "    ext = path.lower().split('.')[-1]\n",
    "    if ext == 'pdf':\n",
    "        if check_pdf_type(path) == 'text':\n",
    "            with open(path, 'rb') as f:\n",
    "                reader = PyPDF2.PdfReader(f)\n",
    "                return \"\".join([page.extract_text() for page in reader.pages])\n",
    "        else:\n",
    "            images = convert_from_path(path)\n",
    "            return \"\".join([pytesseract.image_to_string(img) for img in images])\n",
    "    elif ext in ['docx', 'doc']:\n",
    "        doc = docx.Document(path)\n",
    "        return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "    elif ext == 'txt':\n",
    "        with open(path, 'r', encoding='utf-8') as f: return f.read()\n",
    "    return \"\"\n",
    "\n",
    "def extract_sections_with_regex(text):\n",
    "    sections_found = defaultdict(list)\n",
    "    for act_name, patterns in ACT_PATTERNS.items():\n",
    "        for pattern in patterns:\n",
    "            matches = re.finditer(pattern, text, re.IGNORECASE)\n",
    "            for match in matches:\n",
    "                try:\n",
    "                    section_num = re.sub(r'[^\\d\\w]', '', match.group(1))\n",
    "                    if not section_num or not section_num[0].isdigit(): continue\n",
    "                    sections_found[f\"{act_name}_{section_num}\"].append(match.group(0))\n",
    "                except: continue\n",
    "    return sections_found\n",
    "\n",
    "def load_hybrid_cooccurrence():\n",
    "    if os.path.exists('output/hybrid_cooccurrence.json'):\n",
    "        with open('output/hybrid_cooccurrence.json', 'r') as f:\n",
    "            return json.load(f)\n",
    "    return {}\n",
    "\n",
    "# --- ANALYSIS LOGIC (FIXED) ---\n",
    "def analyze_and_evaluate_single_doc(doc_path):\n",
    "    hybrid_db = load_hybrid_cooccurrence()\n",
    "    if not hybrid_db:\n",
    "        print(\"Error: DB not found. Run Training first.\")\n",
    "        return\n",
    "\n",
    "    text = get_document_text(doc_path)\n",
    "    extracted = extract_sections_with_regex(text)\n",
    "    \n",
    "    if not extracted:\n",
    "        print(\"No sections found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Analyzing: {os.path.basename(doc_path)}\")\n",
    "    print(f\"Extracted: {list(extracted.keys())}\")\n",
    "    \n",
    "    suggestions = {}\n",
    "    extracted_keys = list(extracted.keys())\n",
    "    \n",
    "    for section in extracted_keys:\n",
    "        if section in hybrid_db:\n",
    "            data = hybrid_db[section]\n",
    "            \n",
    "            # 1. Gather Explicit\n",
    "            for rel, count in data.get('explicit_cooccurrence', {}).items():\n",
    "                if rel not in extracted_keys:\n",
    "                    # Initialize with ALL keys to avoid KeyError later\n",
    "                    if rel not in suggestions: \n",
    "                        suggestions[rel] = {'score': 0, 'type': 'explicit', 'count': 0, 'val': 0.0}\n",
    "                    \n",
    "                    suggestions[rel]['score'] += 1.0 \n",
    "                    suggestions[rel]['count'] += count\n",
    "            \n",
    "            # 2. Gather Semantic\n",
    "            for rel, score in data.get('semantic_cooccurrence', {}).items():\n",
    "                if rel not in extracted_keys:\n",
    "                    # Initialize if not exists\n",
    "                    if rel not in suggestions: \n",
    "                        suggestions[rel] = {'score': 0, 'type': 'semantic', 'val': 0.0, 'count': 0}\n",
    "                    \n",
    "                    # Safety check: if it existed from Explicit loop, ensure 'val' key exists\n",
    "                    if 'val' not in suggestions[rel]:\n",
    "                        suggestions[rel]['val'] = 0.0\n",
    "                        \n",
    "                    suggestions[rel]['score'] += score \n",
    "                    suggestions[rel]['val'] = max(suggestions[rel]['val'], score)\n",
    "\n",
    "    sorted_sug = sorted(suggestions.items(), key=lambda x: x[1]['score'], reverse=True)[:5]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TOP 5 SUGGESTIONS & CONFIDENCE METRICS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    confidence_scores = []\n",
    "    \n",
    "    for sec, data in sorted_sug:\n",
    "        # Normalize score\n",
    "        display_score = min(data['score'], 1.0) \n",
    "        \n",
    "        # Heuristic for display confidence\n",
    "        if data['type'] == 'explicit':\n",
    "            # Explicit links are usually very strong, boost based on count\n",
    "            display_score = 0.95 + (0.01 * min(data.get('count', 0), 5))\n",
    "        else:\n",
    "            # Semantic links use the cosine similarity value\n",
    "            display_score = data.get('val', 0.0)\n",
    "            \n",
    "        display_score = min(display_score, 1.0) # Cap at 1.0\n",
    "        confidence_scores.append(display_score)\n",
    "        \n",
    "        # Visual Bar\n",
    "        bar_len = int(display_score * 20)\n",
    "        bar = \"█\" * bar_len + \"░\" * (20 - bar_len)\n",
    "        \n",
    "        print(f\"Section: {sec:<20} | Confidence: {display_score:.2f} | {bar}\")\n",
    "        if sec in hybrid_db and hybrid_db[sec].get('contexts'):\n",
    "            print(f\"   Context: \\\"{hybrid_db[sec]['contexts'][0][:80]}...\\\"\")\n",
    "    \n",
    "    if confidence_scores:\n",
    "        avg_conf = np.mean(confidence_scores)\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"Average Model Confidence: {avg_conf:.4f}\")\n",
    "        \n",
    "        if avg_conf > 0.8: print(\"Metric: Model is VERY CERTAIN about these missing sections.\")\n",
    "        elif avg_conf > 0.5: print(\"Metric: Model has MODERATE certainty.\")\n",
    "        else: print(\"Metric: Model is GUESSING (Low Confidence).\")\n",
    "    else:\n",
    "        print(\"No suggestions found.\")\n",
    "\n",
    "# Run\n",
    "input_file = input(\"Enter filename from 'docs/' to analyze: \")\n",
    "full_path = os.path.join('docs', input_file)\n",
    "if os.path.exists(full_path):\n",
    "    analyze_and_evaluate_single_doc(full_path)\n",
    "else:\n",
    "    print(\"File not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a08efe-d6fd-4c1b-8114-3012a43655aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
